# “阿里灵杰”问天引擎电商搜索算法赛

## 方案简介

### 召回阶段

召回阶段主要分为两步，分别是**领域数据后训练**和**任务数据微调**。

#### 领域数据后训练

##### 数据处理

使用原始比赛数据和官方提供的CPR数据中的train.query、test.query、corpus数据，经过中文简写英文小写转换（follow ernie预训练时的数据处理方式）作为训练和验证数据。

##### 训练

模型使用chinese-roberta-wwm-ext；后训练方式为N-gram mlm。

#### 召回任务微调

##### 数据处理

数据来源为原始比赛数据和官方提供的CPR数据。使用train.query和corpus中对应的doc构建query和正样本doc，并且随机采样（借鉴DPR中的部分负样本构建）corpus中不包含对应query的doc，作为负样本doc。

##### 训练

follow有监督simcse的训练。对于每个query，正样本为对应的doc，负样本为in-batch其它query的对应doc和in-batch随机采样的所有doc，将query和正负doc分别输入模型，使用模型最后一层隐状态的平均值作为对应表示，然后将query表示分别和正负doc表示计算余弦相似度后，计算infoNCE loss。

并且训练时使用FGM对抗训练。

### 精排阶段

精排阶段使用召回阶段后训练的模型，然后使用精排任务微调。

#### 精排任务微调

##### 数据处理

数据来源为原始比赛数据。使用初赛训练好的召回模型，为每个query模拟召回top-k个doc。对于每个query，其正样本为corpus中对应的doc，负样本为模拟召回的top-k中排除正样本后的doc。

##### 训练

follow百度开源的neural_search中的ranking模块。每条训练样本为query，正样本doc，负样本doc，分别将query和正负样本doc凭借后输入模型，取[CLS]向量经过映射后降为1维，然后过sigmoid激活函数作为排序得分，然后使用margin ranking loss计算损失。

并且为了使得训练时降为1维的logits经过sigmoid激活函数后更有区分度，我们将正例pair的logits和负例pair的logits取平均值获得mean logits，然后使用正例pair的logits - mean logits获得新的正例pair的logits，负例pair的logits - mean logits获得新的负例pair的logits。

同时对于margin ranking loss，我们提出了动态margin的策略，即使用模拟召回时负样本对应的召回距离控制margin大小，margin的大小和召回距离的平方成正比。通过这种方式，不相关的负样本由于召回距离大，所以margin更大，使得召回的所有的负样本都能被更全面的优化。

最后使用了R-Drop的方式优化训练过程。

##### 验证

对于验证，考虑到线下验证与线上测试的一致性，线下验证时直接采用和线上相同的排序方式进行验证。每条验证样本为query，正样本（或负样本）doc，同一query的top-k个负样本doc + 1个正样本样本doc组成一个验证集batch，每次计算batch中所有样本对的排序得分，然后进行排序，找到正样本所在的排名计算MRR@10。同时考虑到线上测试时可能无法召回正样本doc，所以我们计算了验证集的召回top-k+1中包含正样本的概率，用这个概率乘MRR@10就可以大致模拟线上的测试集得分。

##### 确定召回top-k以及提交的Rerank_size

首先，通过测试，我们可知base模型的测试Rerank_size大概在35-40之间，所以我们召回的top-k为35，但在提交时，却不是越大越好，而是在中间的某个值时达到最优，经过尝试，我们确定提交的Rerank_size为24。